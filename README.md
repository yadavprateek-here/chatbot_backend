ğŸ¤– OmniBot Backend â€“ Multi-Tenant AI Chatbot API

OmniBot Backend is a scalable, multi-tenant AI chatbot API designed to power plug-and-play chat widgets for any business.
It supports tenant isolation, Retrieval-Augmented Generation (RAG), conversation memory, and LLM provider decoupling.

This backend is framework-agnostic from the frontend perspective and can be integrated with any website or application.

ğŸš€ Features

âœ… Multi-tenant architecture (strict data isolation)

âœ… Secure AI orchestration layer

âœ… RAG-based responses (company data only)

âœ… Optional general-purpose AI mode

âœ… Conversation memory support

âœ… MongoDB-based persistence

âœ… LLM provider agnostic (OpenRouter, Gemini, etc.)

âœ… Ready for SaaS scaling

ğŸ§± Tech Stack
Layer	Technology
Runtime	Node.js
API Framework	Express.js
Database	MongoDB (Mongoose)
AI Provider	OpenRouter (LLMs via API)
Language	TypeScript
Auth	API key (tenant-based)
Architecture	Clean, decoupled services
ğŸ“ Project Structure
src/
â”œâ”€â”€ index.ts                 # App entry point
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ chat.route.ts        # Chat API
â”‚   â”œâ”€â”€ tenant.route.ts      # Tenant CRUD
â”‚   â””â”€â”€ document.route.ts    # Knowledge base CRUD
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai-orchestrator.ts   # LLM + RAG logic
â”‚   â”œâ”€â”€ tenant.service.ts   # Tenant & document access
â”‚   â””â”€â”€ memory.service.ts   # (Optional) conversation memory
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tenant.model.ts
â”‚   â”œâ”€â”€ document.model.ts
â”‚   â””â”€â”€ conversation.model.ts
â””â”€â”€ config/
    â””â”€â”€ db.ts                # MongoDB connection

ğŸ” Environment Variables

Create a .env file in the backend root:

PORT=4000
OPENROUTER_API_KEY=your_openrouter_api_key
MONGODB_URI=mongodb://localhost:27017/admin

ğŸ”Œ MongoDB Setup

Database:

admin


Collections:

Tenant
Document
Conversation (optional)


Example Tenant document:

{
  "_id": "tenant_tutoronline",
  "name": "TutorOnline",
  "systemInstruction": "You are a helpful tutoring assistant.",
  "status": "active"
}


Example Document:

{
  "_id": "doc_001",
  "tenantId": "tenant_tutoronline",
  "title": "Pricing Plans",
  "content": "Basic â‚¹1,999, Pro â‚¹4,999, Premium â‚¹9,999",
  "type": "text",
  "tokens": 120
}

ğŸ“¡ API Endpoints
ğŸ§  Chat API

POST /chat/message

Request
{
  "companyId": "tenant_tutoronline",
  "message": "What is the Premium plan price?",
  "history": []
}

Response
{
  "reply": "The Premium plan costs â‚¹9,999 per month."
}

ğŸ¢ Tenants API

GET /api/tenants
Fetch all tenants

POST /api/tenants
Create a new tenant

{
  "name": "New Company"
}

ğŸ“š Knowledge Base API

GET /api/tenants/:tenantId/documents
Fetch documents for tenant

POST /api/documents
Add document

{
  "tenantId": "tenant_tutoronline",
  "title": "Refund Policy",
  "content": "7-day refund available",
  "type": "text"
}

ğŸ§  AI Orchestration Logic

The AI pipeline works as follows:

Validate tenant

Fetch tenant-specific documents

Build RAG context

Inject conversation memory (optional)

Apply strict system rules

Call LLM provider

Return grounded response

Prompt Hierarchy
System Rules
â†“
Tenant Instructions
â†“
RAG Context
â†“
Conversation Memory
â†“
User Message

ğŸ”’ Security & Isolation

ğŸ” Tenant-based data isolation

ğŸ” No cross-tenant document access

ğŸ” No frontend exposure of API keys

ğŸ” LLM access only via backend

ğŸ” Safe fallback responses

ğŸ§ª Data Isolation Test (Critical)

Tenant A asks:

â€œWhat is the price of the Private Pool Villa?â€

Expected response:

Iâ€™m sorry, I donâ€™t have information on that.


âœ” Confirms multi-tenant isolation

ğŸ§© LLM Provider Decoupling

The backend can switch models without changing business logic.

Supported:

OpenRouter (LLaMA, Mistral, GPT, etc.)

Gemini

Local / self-hosted models (future)

ğŸ“ˆ Scalability Roadmap

Redis-based conversation cache

Vector DB (Pinecone / Qdrant)

Streaming responses

Role-based admin access

Usage-based billing

Webhook notifications

ğŸ§‘â€ğŸ’» Local Development
npm install
npm run dev


Server starts at:

http://localhost:4000

ğŸ“„ License

MIT License
Free to use, modify, and commercialize.

âœ¨ Final Note

This backend is not a demo.
It is designed as a real SaaS-ready AI chatbot platform that can be used by any business in minutes.